{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "[[ 1.00000000e+00  4.08100000e+02  3.15100000e+02  1.34359272e+00]\n",
      " [ 1.00000000e+00  6.40700000e+02  5.19100000e+02  3.45834615e-01]\n",
      " [ 1.00000000e+00  4.04200000e+02  1.18800000e+02  1.70293855e+00]\n",
      " ...\n",
      " [ 3.00000000e+01  1.15500000e+02  3.06100000e+02 -4.09235014e-01]\n",
      " [ 3.00000000e+01  7.32000000e+02  3.10300000e+02 -4.81621022e-01]\n",
      " [ 3.00000000e+01  6.32200000e+02  3.53600000e+02 -4.66137384e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- vit.embeddings.patch_embeddings.projection.weight: found shape torch.Size([768, 3, 16, 16]) in the checkpoint and torch.Size([768, 768, 129, 1]) in the model instantiated\n",
      "- vit.embeddings.position_embeddings: found shape torch.Size([1, 197, 768]) in the checkpoint and torch.Size([1, 15, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create dataloader...\n",
      "HI\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, position loss: 168988.453125 reconstruction loss: 0.0 RMSE(mm): 205.5410257862162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:07, 14.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 100, position loss: 135124.453125 reconstruction loss: 0.0 RMSE(mm): 183.79639082759488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:14, 14.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 200, position loss: 147830.484375 reconstruction loss: 0.0 RMSE(mm): 192.24365033402273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:16, 14.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val Loss: 128878.38025841347, RMSE(mm): 179.49817565814803\n",
      "Epoch 0, test Loss: 139498.98602764422, RMSE(mm): 186.74781526676838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 14.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, position loss: 142764.53125 reconstruction loss: 0.0 RMSE(mm): 188.92096975322775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:07, 14.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, position loss: 115816.140625 reconstruction loss: 0.0 RMSE(mm): 170.15885271195853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [00:13, 14.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 200, position loss: 112698.078125 reconstruction loss: 0.0 RMSE(mm): 167.85267210041667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:15, 14.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Val Loss: 111037.42788461539, RMSE(mm): 166.61139508195063\n",
      "Epoch 1, test Loss: 119315.28635817308, RMSE(mm): 172.71022433412352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 14.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 0, position loss: 100341.65625 reconstruction loss: 0.0 RMSE(mm): 158.3837556774684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:07, 14.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 100, position loss: 43925.08203125 reconstruction loss: 0.0 RMSE(mm): 104.79155742621874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [00:13, 14.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 200, position loss: 24327.87890625 reconstruction loss: 0.0 RMSE(mm): 77.9869843407379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:15, 14.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Val Loss: 20185.039888822117, RMSE(mm): 71.03703240004842\n",
      "Epoch 2, test Loss: 19087.821739783652, RMSE(mm): 69.07934159317034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 14.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 0, position loss: 17397.5390625 reconstruction loss: 0.0 RMSE(mm): 65.94986554667871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:07, 14.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 100, position loss: 12574.34375 reconstruction loss: 0.0 RMSE(mm): 56.06769067386314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [00:13, 14.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 200, position loss: 18178.05859375 reconstruction loss: 0.0 RMSE(mm): 67.41301542311767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:15, 14.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Val Loss: 19042.351243239184, RMSE(mm): 68.9970130571592\n",
      "Epoch 3, test Loss: 18134.266920823316, RMSE(mm): 67.33176613015456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 14.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 0, position loss: 12397.138671875 reconstruction loss: 0.0 RMSE(mm): 55.67121938640064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:06, 14.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 100, position loss: 12104.171875 reconstruction loss: 0.0 RMSE(mm): 55.00948071696369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "202it [00:13, 14.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 200, position loss: 19856.185546875 reconstruction loss: 0.0 RMSE(mm): 70.45598900532694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:15, 14.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Val Loss: 16017.996694711539, RMSE(mm): 63.28111229804581\n",
      "Epoch 4, test Loss: 13865.380690354566, RMSE(mm): 58.875675559509645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 14.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 0, position loss: 11857.8974609375 reconstruction loss: 0.0 RMSE(mm): 54.446986741548656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:06, 14.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 100, position loss: 11432.765625 reconstruction loss: 0.0 RMSE(mm): 53.46205576153989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "202it [00:13, 14.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 200, position loss: 18349.921875 reconstruction loss: 0.0 RMSE(mm): 67.7309417382484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:15, 14.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Val Loss: 16008.72049654447, RMSE(mm): 63.262786250181215\n",
      "Epoch 5, test Loss: 14499.517709585336, RMSE(mm): 60.206971584662305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 14.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 0, position loss: 10471.951171875 reconstruction loss: 0.0 RMSE(mm): 51.166275934141915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:06, 14.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 100, position loss: 11445.576171875 reconstruction loss: 0.0 RMSE(mm): 53.49199980341687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [00:13, 14.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 200, position loss: 12971.1845703125 reconstruction loss: 0.0 RMSE(mm): 56.94555419502145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:15, 14.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Val Loss: 14477.261286808895, RMSE(mm): 60.16074568771753\n",
      "Epoch 6, test Loss: 12296.991858849158, RMSE(mm): 55.44590124357516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 14.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 0, position loss: 8770.2587890625 reconstruction loss: 0.0 RMSE(mm): 46.824829922442056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:07, 14.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 100, position loss: 11014.1240234375 reconstruction loss: 0.0 RMSE(mm): 52.47409842826625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [00:13, 14.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 200, position loss: 12755.3876953125 reconstruction loss: 0.0 RMSE(mm): 56.469876251220214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:15, 14.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Val Loss: 14583.40508563702, RMSE(mm): 60.38088498365401\n",
      "Epoch 7, test Loss: 12193.448176457332, RMSE(mm): 55.21197373862243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 14.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 0, position loss: 8700.2783203125 reconstruction loss: 0.0 RMSE(mm): 46.63764123621739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:07, 14.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 100, position loss: 10310.3525390625 reconstruction loss: 0.0 RMSE(mm): 50.76995307035082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [00:13, 15.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 200, position loss: 12412.232421875 reconstruction loss: 0.0 RMSE(mm): 55.7050994565915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:15, 14.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Val Loss: 14602.01983173077, RMSE(mm): 60.419408785031095\n",
      "Epoch 8, test Loss: 12150.136380709135, RMSE(mm): 55.113828529483264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 15.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 0, position loss: 8462.87890625 reconstruction loss: 0.0 RMSE(mm): 45.9969534487068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:06, 14.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 100, position loss: 9823.60546875 reconstruction loss: 0.0 RMSE(mm): 49.55705163937318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [00:13, 14.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 200, position loss: 12245.0546875 reconstruction loss: 0.0 RMSE(mm): 55.32868760304188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:15, 14.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Val Loss: 14651.110407902645, RMSE(mm): 60.52088566747566\n",
      "Epoch 9, test Loss: 12149.111065204326, RMSE(mm): 55.111503030683906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 14.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 0, position loss: 8112.43798828125 reconstruction loss: 0.0 RMSE(mm): 45.03453671428532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:07, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 100, position loss: 9436.1484375 reconstruction loss: 0.0 RMSE(mm): 48.569919799964666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [00:13, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 200, position loss: 11798.3994140625 reconstruction loss: 0.0 RMSE(mm): 54.31021868410792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:15, 15.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Val Loss: 14722.321467472957, RMSE(mm): 60.66778689608052\n",
      "Epoch 10, test Loss: 12184.521474984977, RMSE(mm): 55.19175997145085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Batch 0, position loss: 7745.337890625 reconstruction loss: 0.0 RMSE(mm): 44.00380066149116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:06, 15.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Batch 100, position loss: 9022.67578125 reconstruction loss: 0.0 RMSE(mm): 47.493883241029046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "202it [00:13, 14.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Batch 200, position loss: 11224.3203125 reconstruction loss: 0.0 RMSE(mm): 52.97244640494716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:15, 15.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Val Loss: 14815.23270357572, RMSE(mm): 60.858920265594016\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\OneDrive - The George Washington University\\Course\\23Fall\\6907AppliedML\\Code\\MTL-VIT2EEG\\pupil_cat_MTL_weight_tune.ipynb 单元格 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/OneDrive%20-%20The%20George%20Washington%20University/Course/23Fall/6907AppliedML/Code/MTL-VIT2EEG/pupil_cat_MTL_weight_tune.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m, gamma\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/OneDrive%20-%20The%20George%20Washington%20University/Course/23Fall/6907AppliedML/Code/MTL-VIT2EEG/pupil_cat_MTL_weight_tune.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m file_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m_weight_test_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/OneDrive%20-%20The%20George%20Washington%20University/Course/23Fall/6907AppliedML/Code/MTL-VIT2EEG/pupil_cat_MTL_weight_tune.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m train(model,EEGEyeNet, optimizer, scheduler,log_name\u001b[39m=\u001b[39;49mfile_name, batch_size \u001b[39m=\u001b[39;49m batch_size ,n_epoch \u001b[39m=\u001b[39;49m n_epoch, subtask_weight\u001b[39m=\u001b[39;49mi)\n",
      "File \u001b[1;32mf:\\OneDrive - The George Washington University\\Course\\23Fall\\6907AppliedML\\Code\\MTL-VIT2EEG\\helper_function_pupil.py:159\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, Dataset, optimizer, scheduler, batch_size, n_epoch, output_dir, subtask_weight, log_name)\u001b[0m\n\u001b[0;32m    157\u001b[0m val_reconstruction_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m    158\u001b[0m \u001b[39mfor\u001b[39;00m inputs, targets,pupil_size, index \u001b[39min\u001b[39;00m test_loader:\n\u001b[1;32m--> 159\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m    160\u001b[0m     targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m    161\u001b[0m     pupil_size \u001b[39m=\u001b[39m pupil_size\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "from dataset.EEGEyeNet_MTL import EEGEyeNetDataset\n",
    "import torch\n",
    "'''\n",
    "models: EEGViT_pretrained; EEGViT_raw; ViTBase; ViTBase_pretrained\n",
    "'''\n",
    "EEGEyeNet = EEGEyeNetDataset('./dataset\\MTL_data_2\\Position_task_with_dots_synchronized_min.npz')\n",
    "from models.EEGViT_pretrained_hierarchical_pupil import EEGViT_pretrained_hierachical2\n",
    "from helper_function_pupil import train\n",
    "batch_size = 64\n",
    "n_epoch = 20\n",
    "learning_rate = 1e-4\n",
    "model_name = 'MTL_std_pupil_cat_VIT_pre_hei'\n",
    "i=0\n",
    "model = EEGViT_pretrained_hierachical2()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)\n",
    "file_name = f'{model_name}_weight_test_{i}'\n",
    "train(model,EEGEyeNet, optimizer, scheduler,log_name=file_name, batch_size = batch_size ,n_epoch = n_epoch, subtask_weight=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- vit.embeddings.patch_embeddings.projection.weight: found shape torch.Size([768, 3, 16, 16]) in the checkpoint and torch.Size([768, 768, 129, 1]) in the model instantiated\n",
      "- vit.embeddings.position_embeddings: found shape torch.Size([1, 197, 768]) in the checkpoint and torch.Size([1, 15, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create dataloader...\n",
      "HI\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Liwei\\AppData\\Local\\Temp\\ipykernel_29236\\2624771002.py\", line 15, in <module>\n",
      "    train(model,EEGEyeNet, optimizer, scheduler,log_name=file_name, batch_size = batch_size ,n_epoch = n_epoch, subtask_weight=i)\n",
      "  File \"f:\\OneDrive - The George Washington University\\Course\\23Fall\\6907AppliedML\\Code\\MTL-VIT2EEG\\helper_function_pupil.py\", line 90, in train\n",
      "    positions, predict_pupil_size = model(inputs,pupil_size)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"f:\\OneDrive - The George Washington University\\Course\\23Fall\\6907AppliedML\\Code\\MTL-VIT2EEG\\models\\EEGViT_pretrained_hierarchical_pupil.py\", line 82, in forward\n",
      "    positions = self.position_predictor(combined_features)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\", line 138, in forward\n",
      "    self._check_input_dim(input)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\", line 416, in _check_input_dim\n",
      "    raise ValueError(f\"expected 4D input (got {input.dim()}D input)\")\n",
      "ValueError: expected 4D input (got 2D input)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import models.EEGViT_pretrained_hierarchical_pupil \n",
    "reload(models.EEGViT_pretrained_hierarchical_pupil )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AppliedML6907",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
