{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "[[1.000e+00 4.081e+02 3.151e+02 3.323e+03]\n",
      " [1.000e+00 6.407e+02 5.191e+02 3.062e+03]\n",
      " [1.000e+00 4.042e+02 1.188e+02 3.417e+03]\n",
      " ...\n",
      " [3.000e+01 1.155e+02 3.061e+02 1.910e+03]\n",
      " [3.000e+01 7.320e+02 3.103e+02 1.723e+03]\n",
      " [3.000e+01 6.322e+02 3.536e+02 1.763e+03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- vit.embeddings.patch_embeddings.projection.weight: found shape torch.Size([768, 3, 16, 16]) in the checkpoint and torch.Size([768, 256, 8, 1]) in the model instantiated\n",
      "- vit.embeddings.position_embeddings: found shape torch.Size([1, 197, 768]) in the checkpoint and torch.Size([1, 225, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create dataloader...\n",
      "HI\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:07,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, position loss: 168865.40625 reconstruction loss: 9829259.0 RMSE(mm): 205.46618106759078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:12,  1.18s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\OneDrive - The George Washington University\\Course\\23Fall\\6907AppliedML\\Code\\MTL-VIT2EEG\\Reconstruct_MTL_weight_tune copy.ipynb 单元格 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/OneDrive%20-%20The%20George%20Washington%20University/Course/23Fall/6907AppliedML/Code/MTL-VIT2EEG/Reconstruct_MTL_weight_tune%20copy.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m, gamma\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/OneDrive%20-%20The%20George%20Washington%20University/Course/23Fall/6907AppliedML/Code/MTL-VIT2EEG/Reconstruct_MTL_weight_tune%20copy.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m file_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m_weight_test_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/OneDrive%20-%20The%20George%20Washington%20University/Course/23Fall/6907AppliedML/Code/MTL-VIT2EEG/Reconstruct_MTL_weight_tune%20copy.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m train(model,EEGEyeNet, optimizer, scheduler,log_name\u001b[39m=\u001b[39;49mfile_name, batch_size \u001b[39m=\u001b[39;49m batch_size ,n_epoch \u001b[39m=\u001b[39;49m n_epoch, subtask_weight\u001b[39m=\u001b[39;49mi)\n",
      "File \u001b[1;32mf:\\OneDrive - The George Washington University\\Course\\23Fall\\6907AppliedML\\Code\\MTL-VIT2EEG\\helper_function_pupil.py:99\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, Dataset, optimizer, scheduler, batch_size, n_epoch, output_dir, subtask_weight, log_name)\u001b[0m\n\u001b[0;32m     97\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     98\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> 99\u001b[0m epoch_train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m    100\u001b[0m epoch_train_position_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m position_loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m    101\u001b[0m epoch_train_reconstruction_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m pupil_size_loss\u001b[39m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models.MTLVit_pretrained_pupil import MTLViT_pretrained\n",
    "from helper_function_pupil import train\n",
    "from dataset.EEGEyeNet_MTL import EEGEyeNetDataset\n",
    "import torch\n",
    "\n",
    "'''\n",
    "models: EEGViT_pretrained; EEGViT_raw; ViTBase; ViTBase_pretrained\n",
    "'''\n",
    "EEGEyeNet = EEGEyeNetDataset('./dataset\\MTL_data\\Position_task_with_dots_synchronized_min.npz')\n",
    "batch_size = 64\n",
    "n_epoch = 30\n",
    "learning_rate = 1e-4\n",
    "model_name = 'MTL_pupil_VIT_pre'\n",
    "i=0.0005\n",
    "model = MTLViT_pretrained()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)\n",
    "file_name = f'{model_name}_weight_test_{i}'\n",
    "train(model,EEGEyeNet, optimizer, scheduler,log_name=file_name, batch_size = batch_size ,n_epoch = n_epoch, subtask_weight=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create dataloader...\n",
      "HI\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MTLViT_pretrained' object has no attribute 'ViT_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mf:\\OneDrive - The George Washington University\\Course\\23Fall\\6907AppliedML\\Code\\MTL-VIT2EEG\\Reconstruct_MTL_weight_tune copy.ipynb 单元格 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/OneDrive%20-%20The%20George%20Washington%20University/Course/23Fall/6907AppliedML/Code/MTL-VIT2EEG/Reconstruct_MTL_weight_tune%20copy.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(model,EEGEyeNet, optimizer, scheduler,log_name\u001b[39m=\u001b[39;49mfile_name, batch_size \u001b[39m=\u001b[39;49m batch_size ,n_epoch \u001b[39m=\u001b[39;49m n_epoch, subtask_weight\u001b[39m=\u001b[39;49mi)\n",
      "File \u001b[1;32mf:\\OneDrive - The George Washington University\\Course\\23Fall\\6907AppliedML\\Code\\MTL-VIT2EEG\\helper_function_pupil.py:89\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, Dataset, optimizer, scheduler, batch_size, n_epoch, output_dir, subtask_weight, log_name)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39m# Compute the outputs and loss for the current batch\u001b[39;00m\n\u001b[0;32m     88\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 89\u001b[0m positions, predict_pupil_size \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     91\u001b[0m position_loss \u001b[39m=\u001b[39m criterion(positions\u001b[39m.\u001b[39msqueeze(), targets\u001b[39m.\u001b[39msqueeze())\n\u001b[0;32m     92\u001b[0m pupil_size_loss \u001b[39m=\u001b[39m criterion(predict_pupil_size\u001b[39m.\u001b[39msqueeze(), pupil_size\u001b[39m.\u001b[39msqueeze())\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\OneDrive - The George Washington University\\Course\\23Fall\\6907AppliedML\\Code\\MTL-VIT2EEG\\models\\MTLVit_pretrained_pupil.py:42\u001b[0m, in \u001b[0;36mMTLViT_pretrained.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n\u001b[0;32m     41\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatchnorm1(x)\n\u001b[1;32m---> 42\u001b[0m positions\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mViT_model\u001b[39m.\u001b[39mforward(x)\u001b[39m.\u001b[39mlogits\n\u001b[0;32m     43\u001b[0m shared_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mViT(x)\u001b[39m.\u001b[39mlast_hidden_state  \u001b[39m# Extracting the shared features\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39m# Position Prediction\u001b[39;00m\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\mlteeg\\lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1694\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1695\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MTLViT_pretrained' object has no attribute 'ViT_model'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AppliedML6907",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
